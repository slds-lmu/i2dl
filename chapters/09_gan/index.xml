<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Topic 09: Generative Adversarial Neural Networks on Introduction to Machine Learning (I2ML)</title><link>https://slds-lmu.github.io/i2dl/chapters/09_gan/</link><description>Recent content in Topic 09: Generative Adversarial Neural Networks on Introduction to Machine Learning (I2ML)</description><generator>Hugo</generator><language>en-us</language><atom:link href="https://slds-lmu.github.io/i2dl/chapters/09_gan/index.xml" rel="self" type="application/rss+xml"/><item><title>Chapter 09.01: Generative Adversarial Networks (GANs)</title><link>https://slds-lmu.github.io/i2dl/chapters/09_gan/09-01-gan-intro/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://slds-lmu.github.io/i2dl/chapters/09_gan/09-01-gan-intro/</guid><description>&lt;p>This subchapter introduces GANs, which consist of a generator and a discriminator competing to create realistic data samples. In addition, key concepts discussed in this subchapter include the minimax loss function and challenges in training, such as stability issues and optimal discriminator requirements.&lt;/p></description></item><item><title>Chapter 09.02: GAN variants</title><link>https://slds-lmu.github.io/i2dl/chapters/09_gan/09-02-gan-var/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://slds-lmu.github.io/i2dl/chapters/09_gan/09-02-gan-var/</guid><description>&lt;p>This subsection introduces key GAN variants that address limitations in traditional GAN training. It covers non-saturating loss, which helps avoid vanishing gradients. Conditional GANs are also discussed, where additional data, such as labels or images, is used to guide the generation process, enabling more controlled and targeted outputs.&lt;/p></description></item><item><title>Chapter 09.03: Challenges for GAN Optimization</title><link>https://slds-lmu.github.io/i2dl/chapters/09_gan/09-03-gan-challenge/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://slds-lmu.github.io/i2dl/chapters/09_gan/09-03-gan-challenge/</guid><description>&lt;p>This subsection covers the main challenges in optimizing GANs, including non-convergence, mode collapse, and oscillating or chaotic behaviors during training.&lt;/p></description></item></channel></rss>
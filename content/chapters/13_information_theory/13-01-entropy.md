---
title: "Chapter 13.01: Entropy"
weight: 13001
---
We introduce entropy, which expresses the expected information for discrete random variables, as a central concept in information theory. 

<!--more-->

### Lecture video

{{< video id="9H-DkQN0nxM" >}}

### Lecture slides

{{< pdfjs file="https://github.com/slds-lmu/lecture_i2ml/tree/master/slides-pdf/slides-info-entropy.pdf" >}}

---
title: "Chapter 13.06: Information Theory for Machine Learning"
weight: 13006
---
In this section, we discuss how information-theoretic concepts are used in machine learning and demonstrate the equivalence of KL minimization and maximum likelihood maximization, as well as how (cross-)entropy can be used as a loss function. 

<!--more-->

### Lecture video

{{< video id="GX4HwGpbkFw" >}}

### Lecture slides

{{< pdfjs file="https://github.com/slds-lmu/lecture_i2ml/tree/master/slides-pdf/slides-info-ml.pdf" >}}

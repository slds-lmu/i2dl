---
title: Literature
---

The course material covers all exam-relevant topics in a quite self-contained manner. 
For more in-depth study, we recommend the following literature. Note that some of the books are rather detailed and involved, and more geared towards a larger lecture in a Master's degree. 

We **recommend to buy and read** at least one standard reference on ML, for BSc level this might be the James, for the MSc level the Hastie, Bishop, Murphy or Alplaydin, the Shalev-Shwartz for a mathematical entry point, and Deep Learning book written by Goodfelow, d2dl.ai for a python and DL entry.

## Helpful References for Prerequisites

If you need to read up on some of the required topics (see [Prerequisites](../prerequisites)), this list might help. We tried to keep it as short as possible. 

- Alex J. Smola (2020): Dive into Deep Learning [URL](https://d2l.ai/index.html) (An interactive deep learning book with code, math, and discussions Provides NumPy/MXNet, PyTorch, and TensorFlow implementations)(free HTML version)
- Goodfellow, Bengio, Courville (2016): Deep Learning [URL](http://www.deeplearningbook.org/) (free HTML version)
- Awesome Deep Learning [URL](https://github.com/ChristosChristofidis/awesome-deep-learning)
- Andrej Karpathy blog [URL](http://karpathy.github.io/)
- Coursera Kurs "Neural Networks for Machine Learning" [URL](https://www.coursera.org/learn/neural-networks#syllabus)

#### Good Websites to have a look 
 - [distill.pub](https://distill.pub/): in-depth explanations of important concepts, worth checking out periodically for new material


#### Optimization / Training of NNs:
 - Why Momentum Really Works: [ULR](https://distill.pub/2017/momentum/)
 - Adam -- latest trends in deep learning optimization [URL](https://towardsdatascience.com/adam-latest-trends-in-deep-learning-optimization-6be9a291375c)
 - Overview of Gradient Descent Optimization Algorithms [URL](https://ruder.io/optimizing-gradient-descent/)
 - Yes you should understand backprop [URL](https://medium.com/@karpathy/yes-you-should-understand-backprop-e2f06eab496b)
 - A Recipe for Training Neural Networks [URL](https://karpathy.github.io/2019/04/25/recipe/)

#### Regularization:
- Regularization for Deep Learning: A Taxonomy [URL](https://arxiv.org/pdf/1710.10686.pdf)

#### CNNs:

- The Sobel and Laplacian Edge Detectors [URL](http://aishack.in/tutorials/sobel-laplacian-edge-detectors/)
- Keras Blog: How convolutional neural networks see the world [URL](https://blog.keras.io/how-convolutional-neural-networks-see-the-world.html)
- The 9 Deep Learning Papers You Need To Know About [URL](https://adeshpande3.github.io/The-9-Deep-Learning-Papers-You-Need-To-Know-About.html)
- Python based visualization repo for CNNs [URL](https://github.com/HarisIqbal88/PlotNeuralNet)
- Computing Receptive Fields of Convolutional Neural Networks [URL](https://distill.pub/2019/computing-receptive-fields/)
- How Convolutional Neural Networks see the World [URL](https://blog.keras.io/how-convolutional-neural-networks-see-the-world.html)
- Attention in Neural Networks and How to Use It [URL](http://akosiorek.github.io/ml/2017/10/14/visual-attention.html)
- Neural Networks - A Systematic Introduction (FU Berlin)[URL](https://page.mi.fu-berlin.de/rojas/neural/neuron.pdf)
- Deep Learning - The Straight Dope (contains notebooks designed to teach deep learning)[URL](https://gluon.mxnet.io/)
- Computing Receptive Fields of Convolutional Neural Networks [URL](https://distill.pub/2019/computing-receptive-fields/)
- Stanford: Convolutional Neural Networks for Visual Recognition
	- [Videos](http://cs231n.stanford.edu/)
	- [Assignements und notes](http://cs231n.github.io/) 
 

#### Autoencoders/Variational Autoencoders
- PCA [URL](http://www.cs.cmu.edu/~guestrin/Class/15781/slides/pca-mdps-annotated.pdf)
- Introducing Variational Autoencoders (in Prose and Code) [URL](https://blog.fastforwardlabs.com/2016/08/12/introducing-variational-autoencoders-in-prose-and.html)
- A Tutorial on Variational Autoencoders [URL](https://arxiv.org/pdf/1606.05908.pdf)

#### Reinforcement Learning
- Statistical Reinforcement Learning (Lecture) [URL](http://nanjiang.cs.illinois.edu/cs598/)
- Practical Reinforcement Learning (Course) [URL](https://github.com/yandexdataschool/Practical_RL)


#### LSTMs:
- Understanding LSTM and its diagrams [URL](https://medium.com/mlreview/understanding-lstm-and-its-diagrams-37e2f46f1714)
- The most comprehensive yet simple and fun RNN/LSTM tutorial on the Internet. [URL](https://ayearofai.com/rohan-lenny-3-recurrent-neural-networks-10300100899b)


#### Hyperparameter Optimization/ Neural Architecture Search
- Using Machine Learning to Explore Neural Network Architecture [URL](https://ai.googleblog.com/2017/05/using-machine-learning-to-explore.html)


#### Software
- [R vs Python: Image Classification with Keras](https://towardsdatascience.com/r-vs-python-image-classification-with-keras-1fa99a8fef9b)
- H20 related stuff: 
	- [Repository that contains the H2O presentation for Trevor Hastie and Rob Tibshirani's Statistical Learning and Data Mining IV course in Washington, DC on October 19, 2016.](https://github.com/ledell/sldm4-h2o)
	- [Deep Learning with H2O - PDF/Book](http://docs.h2o.ai/h2o/latest-stable/h2o-docs/booklets/DeepLearningBooklet.pdf)



### Material for Exercises
- Neural networks Exercises (Part-1) [URL](https://www.r-bloggers.com/neural-networks-exercises-part-1/)
- M. Deisenroth, A. Faisal, C. Ong. Mathematics for Machine Learning. [URL](https://mml-book.github.io/book/mml-book.pdf)
- L. Wassermann. All of Statistics. [URL](http://egrcc.github.io/docs/math/all-of-statistics.pdf)
- H. Wickham, G. Grolemund. R for Data Science. [URL](https://r4ds.had.co.nz/)
- Introductory R course on datacamp.com [URL](https://learn.datacamp.com/courses/free-introduction-to-r)


## Machine Learning

- K. Kersting, C. Lampert, C. Rothkopf. Wie Maschinen Lernen. Springer, 2019. [URL](https://link.springer.com/book/10.1007/978-3-658-26763-6) *German, informal, intuitive introduction to ML. Lower than BSc level, maybe more targeted at pupils or a non-academic audience. Read if you want a very light-weight introduction into the field, or buy as present for relatives and friends if they ask what you are doing.*
- G. James, D. Witten, T. Hastie, R. Tibshirani. An Introduction to Statistical Learning. MIT Press, 2010. [URL](http://www-bcf.usc.edu/~gareth/ISL/) *Beginner-level introduction with applications in R. Very well suited for the BSc level.*
- T. Hastie, R. Tibshirani, J. Friedman. The Elements of Statistical Learning. Springer, 2009. [URL](https://web.stanford.edu/~hastie/ElemStatLearn/) *Standard reference for statistics-flavored ML.*
- C. M. Bishop. Pattern Recognition and Machine Learning. Springer, 2006. [URL](http://research.microsoft.com/en-us/um/people/cmbishop/prml/) *Standard reference for ML-flavored ML.*
- S. Shalev-Shwartz, S. Ben-David. Understanding machine learning: From Theory to Algorithms. Cambridge University Press, 2014. [URL](https://www.cs.huji.ac.il/w~shais/UnderstandingMachineLearning/) *Great, thorough introduction to ML theory. Math-style book with definitions and proofs.*
- E. Alpaydin. Introduction to Machine Learning. MIT Press, 2010. [URL](http://www.cmpe.boun.edu.tr/~ethem/i2ml2e/) *Standard reference with broad coverage; easy to read.*
- K. Murphy. Machine Learning: a Probabilistic Perspective. MIT Press, 2012. [URL](https://probml.github.io/pml-book/book0.html) *Standard reference; quite extensive; statistical/probabilistic lens.*
- F. Provost, T. Fawcett. Data Science for Business. Oâ€™Reilly, 2013. [URL](https://book.akij.net/eBooks/2018/May/5aef50939a868/Data_Science_for_Bus.pdf) *A very good, applied and easy-to-read book by 2 well-known ML scientists. Contains many practical aspects that are missing in other references. Probably a good idea to read this in any case.*
- N. Japkowicz. Evaluating Learning Algorithms (A Classification Perspective). Cambridge University Press, 2011. *Nice reading on performance measures, resampling methods and (some) statistical tests for benchmarking in ML; only for classification.*
- B. Bischl et al. Hyperparameter Optimization: Foundations, Algorithms, Best Practices and Open Challenges. arXiv preprint 2021. [URL](https://arxiv.org/pdf/2107.05847.pdf) *Our tutorial paper on HPO.*
- I. Goodfellow, Y. Bengio, A. Courville. Deep Learning. MIT Press, 2016. [URL](https://www.deeplearningbook.org/) *Standard, modern reference for DL.*

## Mathematical & Statistical Theory

- G. Strang. Linear Algebra and Learning from Data. Cambridge University Press, 2019. *Serious course on matrices and applied linear algebra.*
- S. Axler. Linear Algebra Done Right. Springer, 2015. [URL](https://link.springer.com/content/pdf/10.1007%2F978-3-319-11080-6.pdf) *Linear Algebra from a more theoretical but still beginner-friendly perspective*
- A. M. Mood, F. A. Graybill, D. C. Boes. Introduction to the Theory of Statistics, McGraw-Hill 1974. [URL](https://www.fulviofrisone.com/attachments/article/446/Introduction%20to%20the%20theory%20of%20statistics%20by%20MOOD.pdf) *Beginner-friendly intro to statistics; bit on the mathy side.*
- J. Watt, R. Borhani, A. Katsaggelos. Machine Learning Refined. Cambridge University Press, 2020. [URL](https://github.com/jermwatt/machine_learning_refined) *Check chapters 2-4 plus Appendix for insightful explanations and visualizations of a variety of optimization concepts.*
- T. M. Cover, J. A. Thomas. Elements of Information Theory. Wiley, 2006. [URL](http://staff.ustc.edu.cn/~cgong821/Wiley.Interscience.Elements.of.Information.Theory.Jul.2006.eBook-DDU.pdf) *Good intro to information theory in first hundred pages, though lacking cross-connections to ML / statistics.*

## Python Programming

- J. VanderPlas. Python Data Science Handbook: Essential Tools for working with Data. 2016. 
Or use the online website such as:
- Python Programming [URL](https://pythonprogramming.net/)
- Python Tutorial [URL](https://www.pythontutorial.net/)


## R Programming

- N. Matloff. The Art of R Programming. No Starch Press, 2011. [URL](https://diytranscriptomics.com/Reading/files/The%20Art%20of%20R%20Programming.pdf)

We use the **mlr3** package for machine learning in R quite heavily.
- Central project page and learning resources: https://mlr3.mlr-org.com/, in particular
  - the [book](https://mlr3book.mlr-org.com/),
  - the [gallery](https://mlr3gallery.mlr-org.com/), and   
  - the [cheatsheets](https://cheatsheets.mlr-org.com/).
- GitHub page: https://github.com/mlr-org/mlr3

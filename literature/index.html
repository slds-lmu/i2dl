<!DOCTYPE html>
<html><head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.0.2/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-EVSTQN3/azprG1Anm3QDgpJLIm9Nao0Yz1ztcQTwFspd3yD65VohhpuuCOmLASjC" crossorigin="anonymous">
<link rel="stylesheet" type="text/css" href="/i2dl/css/style.css">


<title>Introduction to Machine Learning (I2ML) | Literature</title>


<link rel="apple-touch-icon" sizes="180x180" href="/i2dl/apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="/i2dl/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="/i2dl/favicon-16x16.png">
<link rel="manifest" href="/i2dl/site.webmanifest">
<link rel="mask-icon" href="/i2dl/safari-pinned-tab.svg" color="#5bbad5">
<meta name="msapplication-TileColor" content="#da532c">
<meta name="theme-color" content="#ffffff">

</head><body>
<img id="logo" src="/i2dl/i2ml.svg" />

<div id="nav-border" class="container">
    <nav id="nav" class="nav justify-content-center">
        
        <a class="nav-link" href="/i2dl">
        
        Home
        </a>
        
        <a class="nav-link" href="/i2dl/chapters/">
        
        Chapters
        </a>
        
        <a class="nav-link" href="/i2dl/exercises/">
        
        Exercises
        </a>
        
        <a class="nav-link" href="/i2dl/appendix/">
        
        Appendix
        </a>
        
        <a class="nav-link" href="/i2dl/prerequisites/">
        
        Prerequisites
        </a>
        
        <a class="nav-link" href="/i2dl/literature/">
        
        Literature
        </a>
        
        <a class="nav-link" href="/i2dl/team/">
        
        Team
        </a>
        
        <a class="nav-link" href="/i2dl/news/">
        
        News
        </a>
        
    </nav>
</div><div id="content" class="container">
<h1>Literature</h1>

<p><p>The course material covers all exam-relevant topics in a quite self-contained manner.
For more in-depth study, we recommend the following literature. Note that some of the books are rather detailed and involved, and more geared towards a larger lecture in a Master&rsquo;s degree.</p>
<p>We <strong>recommend to buy and read</strong> at least one standard reference on ML, for BSc level this might be the James, for the MSc level the Hastie, Bishop, Murphy or Alplaydin, the Shalev-Shwartz for a mathematical entry point.</p>
<h2 id="helpful-references-for-prerequisites">Helpful References for Prerequisites</h2>
<p>If you need to read up on some of the required topics (see <a href="../prerequisites">Prerequisites</a>), this list might help. We tried to keep it as short as possible.</p>
<ul>
<li>M. Deisenroth, A. Faisal, C. Ong. Mathematics for Machine Learning. <a href="https://mml-book.github.io/book/mml-book.pdf">URL</a></li>
<li>L. Wassermann. All of Statistics. <a href="http://egrcc.github.io/docs/math/all-of-statistics.pdf">URL</a></li>
<li>H. Wickham, G. Grolemund. R for Data Science. <a href="https://r4ds.had.co.nz/">URL</a></li>
<li>Introductory R course on datacamp.com <a href="https://learn.datacamp.com/courses/free-introduction-to-r">URL</a></li>
</ul>
<h2 id="machine-learning">Machine Learning</h2>
<ul>
<li>K. Kersting, C. Lampert, C. Rothkopf. Wie Maschinen Lernen. Springer, 2019. <a href="https://link.springer.com/book/10.1007/978-3-658-26763-6">URL</a> <em>German, informal, intuitive introduction to ML. Lower than BSc level, maybe more targeted at pupils or a non-academic audience. Read if you want a very light-weight introduction into the field, or buy as present for relatives and friends if they ask what you are doing.</em></li>
<li>G. James, D. Witten, T. Hastie, R. Tibshirani. An Introduction to Statistical Learning. MIT Press, 2010. <a href="http://www-bcf.usc.edu/~gareth/ISL/">URL</a> <em>Beginner-level introduction with applications in R. Very well suited for the BSc level.</em></li>
<li>T. Hastie, R. Tibshirani, J. Friedman. The Elements of Statistical Learning. Springer, 2009. <a href="https://web.stanford.edu/~hastie/ElemStatLearn/">URL</a> <em>Standard reference for statistics-flavored ML.</em></li>
<li>C. M. Bishop. Pattern Recognition and Machine Learning. Springer, 2006. <a href="http://research.microsoft.com/en-us/um/people/cmbishop/prml/">URL</a> <em>Standard reference for ML-flavored ML.</em></li>
<li>S. Shalev-Shwartz, S. Ben-David. Understanding machine learning: From Theory to Algorithms. Cambridge University Press, 2014. <a href="https://www.cs.huji.ac.il/w~shais/UnderstandingMachineLearning/">URL</a> <em>Great, thorough introduction to ML theory. Math-style book with definitions and proofs.</em></li>
<li>E. Alpaydin. Introduction to Machine Learning. MIT Press, 2010. <a href="http://www.cmpe.boun.edu.tr/~ethem/i2ml2e/">URL</a> <em>Standard reference with broad coverage; easy to read.</em></li>
<li>K. Murphy. Machine Learning: a Probabilistic Perspective. MIT Press, 2012. <a href="https://probml.github.io/pml-book/book0.html">URL</a> <em>Standard reference; quite extensive; statistical/probabilistic lens.</em></li>
<li>F. Provost, T. Fawcett. Data Science for Business. O’Reilly, 2013. <a href="https://book.akij.net/eBooks/2018/May/5aef50939a868/Data_Science_for_Bus.pdf">URL</a> <em>A very good, applied and easy-to-read book by 2 well-known ML scientists. Contains many practical aspects that are missing in other references. Probably a good idea to read this in any case.</em></li>
<li>N. Japkowicz. Evaluating Learning Algorithms (A Classification Perspective). Cambridge University Press, 2011. <em>Nice reading on performance measures, resampling methods and (some) statistical tests for benchmarking in ML; only for classification.</em></li>
<li>B. Bischl et al. Hyperparameter Optimization: Foundations, Algorithms, Best Practices and Open Challenges. arXiv preprint 2021. <a href="https://arxiv.org/pdf/2107.05847.pdf">URL</a> <em>Our tutorial paper on HPO.</em></li>
<li>I. Goodfellow, Y. Bengio, A. Courville. Deep Learning. MIT Press, 2016. <a href="https://www.deeplearningbook.org/">URL</a> <em>Standard, modern reference for DL.</em></li>
</ul>
<h2 id="mathematical--statistical-theory">Mathematical &amp; Statistical Theory</h2>
<ul>
<li>G. Strang. Linear Algebra and Learning from Data. Cambridge University Press, 2019. <em>Serious course on matrices and applied linear algebra.</em></li>
<li>S. Axler. Linear Algebra Done Right. Springer, 2015. <a href="https://link.springer.com/content/pdf/10.1007%2F978-3-319-11080-6.pdf">URL</a> <em>Linear Algebra from a more theoretical but still beginner-friendly perspective</em></li>
<li>A. M. Mood, F. A. Graybill, D. C. Boes. Introduction to the Theory of Statistics, McGraw-Hill 1974. <a href="https://www.fulviofrisone.com/attachments/article/446/Introduction%20to%20the%20theory%20of%20statistics%20by%20MOOD.pdf">URL</a> <em>Beginner-friendly intro to statistics; bit on the mathy side.</em></li>
<li>J. Watt, R. Borhani, A. Katsaggelos. Machine Learning Refined. Cambridge University Press, 2020. <a href="https://github.com/jermwatt/machine_learning_refined">URL</a> <em>Check chapters 2-4 plus Appendix for insightful explanations and visualizations of a variety of optimization concepts.</em></li>
<li>T. M. Cover, J. A. Thomas. Elements of Information Theory. Wiley, 2006. <a href="http://staff.ustc.edu.cn/~cgong821/Wiley.Interscience.Elements.of.Information.Theory.Jul.2006.eBook-DDU.pdf">URL</a> <em>Good intro to information theory in first hundred pages, though lacking cross-connections to ML / statistics.</em></li>
</ul>
<h2 id="r-programming">R Programming</h2>
<ul>
<li>N. Matloff. The Art of R Programming. No Starch Press, 2011. <a href="https://diytranscriptomics.com/Reading/files/The%20Art%20of%20R%20Programming.pdf">URL</a></li>
</ul>
<p>We use the <strong>mlr3</strong> package for machine learning in R quite heavily.</p>
<ul>
<li>Central project page and learning resources: <a href="https://mlr3.mlr-org.com/">https://mlr3.mlr-org.com/</a>, in particular
<ul>
<li>the <a href="https://mlr3book.mlr-org.com/">book</a>,</li>
<li>the <a href="https://mlr3gallery.mlr-org.com/">gallery</a>, and</li>
<li>the <a href="https://cheatsheets.mlr-org.com/">cheatsheets</a>.</li>
</ul>
</li>
<li>GitHub page: <a href="https://github.com/mlr-org/mlr3">https://github.com/mlr-org/mlr3</a></li>
</ul>
</p>


<div class="chapter_overview">
<ul class="list-unstyled">

</ul>
</div>


        </div><footer class="bg-light text-center text-lg-start fixed-bottom">
<ul class="list-inline text-center">
  <li class="list-inline-item">© 2022 Course Creator</li>
  
  <li class="list-inline-item"><a class="nav-link" href="/i2dl" target="_blank">Main Course Website</a></li>
  
  <li class="list-inline-item"><a class="nav-link" href="https://github.com/slds-lmu/lecture_i2dl" target="_blank">Material Source Code</a></li>
  
  <li class="list-inline-item"><a class="nav-link" href="https://github.com/slds-lmu/i2dl" target="_blank">Website Source Code</a></li>
  
</ul>
</footer>

<script>
  MathJax = {
    tex: {
      inlineMath: [['$', '$'], ['\\(', '\\)']],
      displayMath: [['$$','$$'], ['\\[', '\\]']],
      processEscapes: true,
      processEnvironments: true
    },
    options: {
      skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre'],
      ignoreHtmlClass: ['quizdown']
    }
  };

  window.addEventListener('load', (event) => {
      document.querySelectorAll("mjx-container").forEach(function(x){
        x.parentElement.classList += 'has-jax'})
    });

</script>
<script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
<script type="text/javascript" id="MathJax-script" async
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>

</body>
</html>
